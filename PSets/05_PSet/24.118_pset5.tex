\documentclass[12pt,letterpaper]{article}
\usepackage{../pset_2024}


%Questions and Answers
\qa{q} % a="answers only"; q ="questions only"; b="both"
\usepackage{../qa}


\begin{document}

\psintro{Problem Set 5: Newcomb's Problem}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\question{
\subsection*{Notation:} 

\subsubsection*{A. Evidential Decision Theory} 


According to Evidential Decision Theorists, the \textbf{expected value} of an option $A$ is the weighted average of the values of $A$'s possible outcomes, with weights determined by the probability of the relevant state of affairs, given that you choose $A$. Formally:
\[
EV(A) = v(A S_1) \cdot p(S_1|{}A) +  v(A S_2) \cdot p(S_2|{}A) + \ldots +  v(A S_n) \cdot p(S_n|{}A)
\]
where $S_1, S_2,\ldots S_n$ is any list of (exhaustive and mutually exclusive) states of the world, $v(A S_i)$ is the value of being in a situation in which you've chosen $A$ and $S_i$ is the case, and $p(S|A)$ is the probability of $S$, given that you choose $A$.

Evidential Decision Theorists endorse the following principle:
\begin{description}
\item[Expected Value Maximization]
In any decision problem, you ought to choose an option whose expected value is at least as high as that of any rival option.
\end{description}


\subsubsection*{B. Causal Decision Theory} 

Causal Decision Theorists prefer a different way of calculating expected value. To avoid confusion, I shall refer to the causalist's notion as \textbf{expected causal utility}. 

The {expected causal utility} of an option $A$ is the weighted average of the values of $A$'s possible outcomes, with weights determined by the probability of the following subjunctive conditional: \emph{were you to perform $A$, the outcome would come about}. Formally:
\[
ECU(A) = v(A S_1) \cdot p(A \ \Box\hspace{-1.6mm}\rightarrow S_1) +  v(A S_2) \cdot p(A \ \Box\hspace{-1.6mm}\rightarrow S_2) + \ldots +  v(A S_n) \cdot p(A \ \Box\hspace{-1.6mm}\rightarrow S_n)
\]
where $S_1, S_2,\ldots S_n$ is any list of (exhaustive and mutually exclusive) states of the world, $v(A S_i)$ is the value of being in a situation in which you've chosen $A$ and $S_i$ is the case, and $A \ \Box\hspace{-1.6mm}\rightarrow S_i$ is the claim that $S_i$ would come about were you to perform $A$. 

Note that in the special case in which each $S_i$ ($i \leq n$) is a state of the world whose obtaining or not is causally independent of action $A$, $A \ \Box\hspace{-1.6mm}\rightarrow S_i$ is equivalent to $S_i$. So we get:
\[
ECU(A) = v(A S_1) \cdot p(S_1) +  v(A S_2) \cdot p(S_2) + \ldots +  v(A S_n) \cdot p(S_n)
\]


Causal Decision Theorists endorse the following principle:
\begin{description}
\item[Expected Causal Utility Maximization]
In any decision problem, you ought to choose an option whose expected causal utility is at least as high as that of any rival option.
\end{description}



\subsubsection*{C. Your Value Function} 


Throughout the problem set we will assume that you value only money (and value it linearly): you assign value \(n\) to a situation in which you net \(\$n\).
}

\subsection*{Part I (Quiz on Canvas: 28 points)} 





\begin{enumerate}




\item \question{There are two boxes before you, Left Box and Right Box. You have two options:
\begin{description}
\item[Left] Take the contents of the Left Box only.
\item[Right] Take the contents of the Right Box only.
\end{description}
Predictor has placed \$100 in one of the boxes, but you don't know which. What you do know is that last night Predictor made a prediction about whether you would choose Left or Right. The predictor is your friend: if she predicted Left, she put the money in Left Box; if she predicted Right, she put the money in Right Box. Predictor is 90\% reliable:
$$
p(\text{LeftPredicted}|\text{Left}) =  p(\text{RightPredicted}|\text{Right})  = 0.9
$$
The boxes have been filled ahead of time and your choice will not cause their contents to change. (So, for example, if Predictor placed the \$100 in Left Box, were you to choose Left, the money would still be in Left Box, and were you to choose Right, the money would still be in Left Box. )
}

\begin{enumerate}

\item \question{What is the expected value of choosing Left? (2 points)
}



%\item \question{What is the expected value of choosing Right? (2 points)}

\item \question{Is the expected value of choosing Right ``greater than'', ``less than', or the ``same as'' the EV of choosing Left? (2 points)
}





\item \question{Assume that you see yourself as equally likely to choose Left and Right, and therefore that $p(\text{LeftPredicted}) =  p(\text{RightPredicted})  = 0.5$.\\
%\footnote{I'll ask you to prove this entailment in Problem Set 6. 
%See end of document for proof
%} 
 What is the expected causal utility of choosing Left? (2 points)
}




\item \question{Is the expected causal utility of choosing Right ``greater than'', ``less than', or the ``same as'' the ECU of choosing Left? (2 points)
}


\end{enumerate}


\item[2.--5.]: See the Canvas Quiz for Part 1 for questions 2 thru 5!





\end{enumerate}





%%%%%%%%%
%PART II
%%%%%%%


\subsection*{Part II (Submit PDF on Canvas: 72 points)} 






\begin{enumerate}
 \setcounter{enumi}{5}
 
 
 \com{ %left out for 2023, in light of similar canvas questions; could use for in-class practice 
 \item
   \question{You are finally planning to do something fun over the weekend and are going to a concert. There are two ways of getting there: 
   %note: could automate this question 
   \begin{description}
\item[Taxi] Take a taxi. 

\item[Car]  Drive your car.
  
   \end{description}
   Taking a taxi is expensive ($\$41$). Driving there would cost you only gas money ($\$2$), but there might be a robber at the parking lot. If he's there, he'll steal your boom box, and you'll have to spend $\$130$ to replace it. (At home, your boom box is safe.)}
   
   \begin{enumerate}
   
\item \question{Assume that your two options have the same expected value and that the robber's presence in the parking lot is independent of whether you drive (i.e. $p(\text{RobberInLot}) = p(\text{RobberInLot}|\text{Car})$). What is the probability that the robber will be at the parking lot? (5 points; don't forget to justify your answer.)}



\item \question{Now suppose that the robber has a (perfectly accurate) informant who will tell him whether you'll be driving to the concert. If you drive to the concert, he'll be there with probability 50\%. If not, he won't show up.

According to the Principle of Expected Value Maximization, should you drive or should you take a cab? (5 points; don't forget to justify your answer.)}


   \end{enumerate}

} %end com 






\item \question{There are two boxes before you: Open and Closed. Open contains \$10. You cannot see the contents of Closed, but you are told that it is either completely empty or contains \$100. You have two options: 

\begin{description}
\item[One-Box] Take the contents of Closed and leave the contents of Open behind.
\item[Two-Box] Take the contents of both boxes.
\end{description}
The boxes have been filled ahead of time and your choice will not cause their contents to change.  (So, for example, if Closed contains \$100, were you to One-Box, it would still contain \$100, and were you to Two-Box, it would still contain \$100.)}

\begin{enumerate}




\item \label{ex:coin}
 \question{
There is no predictor. Instead, a fair coin was flipped. If it landed Heads, Closed was filled with \$100; if it landed Tails, Closed was left empty.  All this happened yesterday and your choice will not cause the contents of the boxes to change.

According to the Principle of Expected Value Maximization, should you one-box or two-box? (8 points; don't forget to justify your answer.)
}



\item \question{Same setup as (\ref{ex:coin}). According to the Principle of Expected Causal Utility Maximization, should you one-box or two-box? (8 points; justify answer)}





\item \label{ex:pred}
\question{
Now assume there is a predictor. Yesterday evening, Predictor was enlisted to make a prediction about whether you would one-box or two-box. If Predictor predicted that you would one-box, the \$100 dollars was placed in Closed. Otherwise, Closed was left empty. The probability that Predictor guesses correctly is 60\%. The boxes have now been sealed and their contents will not be changed.  

According to the Principle of Expected Value Maximization, should you one-box or should you two-box? (8 points; don't forget to justify your answer!)
 }
 
 





\item \question{Same setup as (\ref{ex:pred}). According to the Principle of Expected Causal Utility Maximization, should you one-box or should you two-box? (8 points; don't forget to justify your answer.)}





\item \question{Same setup as (\ref{ex:pred}), except that this time you learn that Closed has \$100.

According to the Principle of Expected Value Maximization, should you one-box or should you two-box? (10 points; don't forget to justify your answer.)}



\item \question{Same setup as (\ref{ex:pred}), except that this time you learn that Closed has \$0.

According to the Principle of Expected Value Maximization, should you one-box or should you two-box? (10 points; don't forget to justify your answer.)}


\item \label{ex:certain}
\question{Same setup as (\ref{ex:pred}), except for the following. It is now time $t_0$ and you have no idea whether Closed contains \$100 or \$0. At a later time $t_2$ you must decide whether to one-box or two-box. At time $t_1$ between $t_0$ and $t_2$ you will learn the contents of Closed.

Assume that you're certain that you always choose in accordance with the Principle of Expected Value Maximization. What should you believe at time $t_0$ about what your decision at time $t_2$ will be? (10 points; justify your answer.)}



\item \question{Same setup as (\ref{ex:pred}), except for the following. It is now time $t_0$ and you have no idea whether Closed contains \$100 or \$0. At a later time $t_2$ you must decide whether to one-box or two-box. At time $t_1$ between $t_0$ and $t_2$ you will be \emph{offered the chance} to learn the contents of Closed.

Assume that you're certain that you always choose in accordance with the Principle of Expected Value Maximization. According to the Principle of Expected Value Maximization, should you choose, at $t_1$, to learn the contents of Closed or should you choose to remain ignorant? Is that answer intuitively correct? (10~points; don't forget to justify your answer and discuss its significance.)}



\end{enumerate}



\com{  % start com for Dicing with Death example (issue is that students could google this?)
\item \question{
There are two boxes before you, Left Box and Right Box. You have three options:\footnote{This example is due to Arif Amhed. %See his ``Dicing with Death," \emph{Analysis} 74: 587-592, 2014.
} 
\begin{description}
\item[Left] Take the contents the Left Box only.
\item[Right] Take the contents the Right Box only.
\item[Coin] Pay \$1 for the privilege of flipping a coin. If it lands Heads you keep the contents of Left Box; if it lands Tails, you keep the contents of Right Box.
\end{description}
Predictor has placed \$100 in one of the boxes, but you don't know which. What you do know is that last night Predictor made a prediction about whether you would choose Left, Right, or Coin. Unfortunately for you, {the predictor is evil}. If she predicted Left, she put the money in Right Box; if she predicted Right, she put the money in Left Box.  If she predicted Coin, she flipped a fair coin. If it landed Heads she put the money in Right Box, if it landed Tails, she put the money in Left Box. Predictor is 100\% reliable:
$$
p(\text{LeftPredicted}|\text{Left}) =  p(\text{RightPredicted}|\text{Right}) =  p(\text{CoinPredicted}|\text{Coin}) = 1
$$
The boxes have been filled ahead of time, and their contents will not be changed. (Suppose, for example, that Predictor placed the \$100 in Left Box. Were you to choose Left, the money would still be in Left Box, were you to choose Right, the money would still be in Left Box, and were you to pick Coin, the money would still be in Left Box.)
}

\begin{enumerate}

\item \question{
According to the Principle of Expected Value Maximization, which of the three options should you choose? (10~points; don't forget to justify your answer.)
}



\item \label{ex:three} 
\question{
Assume that you see yourself as equally likely to choose Left, Right, and Coin, and therefore that $p(\text{LeftPredicted}) =  p(\text{RightPredicted})  = p(\text{CoinPredicted}) = 1/3$. According to the Principle of Expected Causal Utility Maximization, which of the three options should you choose? (10~points; don't forget to justify your answer.)}



\item \question{\textbf{Extra Credit:} Does your answer to (4b) undermine Causal Decision Theory? (5 points; credit will be awarded with extreme stinginess and will be  based on how effectively you are able to make your case; you may avail yourself of 250 words)}




\end{enumerate}
}
\com{
\item \question{Consider a Newcomb-style setup in which the small box contains $n$ dollars and the large box contains either $m$ dollars or nothing. How accurate must the predictor be in order for the Principle of Expected Value Maximization to recommend 1-boxing? (6 points)}


}
\com{
\item \question{


Suppose you are considering whether to buy a lottery ticket. The ticket costs \$1, and has a 5\% chance of winning. If you win, you get \$100; otherwise you get nothing.  }

\begin{enumerate}

\item \question{What is the expected value of buying a ticket? (5 points)}

  \answer
 


\item \question{What is the expected value of not buying a ticket? (5 points)}



\end{enumerate}
}  % end com 


\com{ %left out for 2023 version
   
   \item \question{Recall that $A$ and $B$ are \textbf{causally independent} of one another if neither of them is a cause of the other, and that $A$ is \textbf{probabilistically dependent} on $B$ if $p(\text{$A$ occurs}) \neq p(\text{$A$ occurs}|\text{$B$ occurs})$.}

Give an example of a pair of events $A$ and $B$ such that: (1) $A$ and $B$ are causally independent of one another but $(2)$ $A$ is probabilistically dependent on $B$. Make sure your example is significantly different from any cases mentioned in lecture or in the course materials. (6~points; don't forget to explain your answer)



} % end com 

\com{  % begin com 
\item \question{You are considering whether to study for tomorrow's exam. There is a cost associated with studying,  but it is much smaller than the cost of failing the exam. Studying for the exam will cause you to pass; not studying will cause you to fail.

Now suppose that a time traveler who you know to be perfectly reliable informs you that you will, in fact, fail the exam.}

\begin{enumerate}

\item \question{Will you study for the exam? (10 points)}



\item \question{Should you study for the exam? (10 points)}

\end{enumerate}
}





\end{enumerate}

\end{document}


A question Hunt automated for the Canvas Quiz: 

\item \question{
The following example is due to MIT philosopher Caspar Hare:
\begin{quote}

\textbf{Symmetrical Worlds} Imagine that the universe is divided in two along a plane. As far as anyone can tell, the universe is completely symmetrical across this plane: what happens on one side is an exact mirror image of what happens on the other side. The plane is a great tourist attraction. People go up to the plane to peer into the other side, and invariably see their symmetrical twin peering back at them. 

The plane alternates between being opaque and transparent, and scientists have established that when the plane is opaque, there are no causal interactions between events on different sides of the plane. A favorite activity of visitors is to wait until the plane turns opaque, and unveil some crazy prop or hold some ridiculous pose, only to find their twin displaying the same crazy prop or holding the same ridiculous pose when the plane turns transparent.

You are having fun with your symmetry twin when then plane turns opaque. A mysterious but credible stranger comes up to you and offers you a deal. ``Here is a thousand dollars,'' she says.``It's yours to keep. But consider this: my symmetrical twin is right now giving your twin, on the other side of the opaque plane, a thousand dollars. If your twin burns her thousand dollars, I will give you a million dollars. Here is a lighter!"
\end{quote}


}

\begin{enumerate}

\item \question{According to an Evidential Decision Theorist, should you burn the thousand or not burn the thousand? (5 points; don't forget to justify your answer)}

  


\item \question{According to a Causal Decision Theorist, should you burn the thousand or not burn the thousand? (5 points; don't forget to justify your answer)}


\end{enumerate}








%%%%%%%%%%
OLD questions
%%%%%%%%%%





%left out for variety

\com{
\item \question{Consider a Newcomb-style setup in which the small box contains $n$ dollars and the large box contains either $m$ dollars or nothing. How accurate must the predictor be in order for the Principle of Expected Value Maximization to recommend 1-boxing? (10 points)}



}






%left out for variety
\com{
\item \question{


Suppose you are considering whether to buy a lottery ticket. The ticket costs \$1, and has a 5\% chance of winning. If you win, you get \$100; otherwise you get nothing.  }

\begin{enumerate}

\item \question{What is the expected value of buying a ticket? (5 points)}

 


\item \question{What is the expected value of not buying a ticket? (5 points)}



\end{enumerate}
   }


 


  
    
      %%Hunt put some of these on the quiz part, for Part 1; could use some for in-class practice! 
%left out for variety
\com{      
\item 
\question{Of each of the conditionals below, say whether it is indicative or subjunctive. (You might find it helpful to look at Section~5.4.2 of the lecture notes.)}

\begin{enumerate}

\item \question{If you lived here, you'd be home by now. (2 points)}


% LEFT OUT FOR VARIETY
\com{
\item \question{If I left the door open, the cat escaped. (2 points)}

}

\item \question{If Abraham Lincoln hadn't gone to the theater, he wouldn't have been assassinated. (2 points)}


% LEFT OUT FOR TO ADD VARIETY
\com{
\item \question{If you come pick me up from the train station, I'll buy you dinner. (2 points)}

}

\item \question{If she promised she would be here, she'll be here. (2 points)}


\item \question{If you had listened more carefully, we wouldn't be having this conversation. (2~points)}



\item \question{I would have gone to the party, had I been in the mood. (2 points)}



\end{enumerate}
}









%Left out for variety
\com{

\item \question{Recall that $A$ and $B$ are \textbf{causally independent} of one another if neither of them is a cause of the other, and that $A$ is \textbf{probabilistically dependent} on $B$ if $p(\text{$A$ occurs}) \neq p(\text{$A$ occurs}|\text{$B$ occurs})$.}

Give an example of a pair of events $A$ and $B$ such that: (1) $A$ and $B$ are causally independent of one another but $(2)$ $A$ is probabilistically dependent on $B$. Make sure your example is significantly different from any cases mentioned in lecture or in the course materials. (10~points; don't forget to explain your answer)



\item \question{You are considering whether to study for tomorrow's exam. There is a cost associated with studying,  but it is much smaller than the cost of failing the exam. Studying for the exam will cause you to pass; not studying will cause you to fail.

Now suppose that a time traveler who you know to be perfectly reliable informs you that you will, in fact, fail the exam.}

\begin{enumerate}

\item \question{Will you study for the exam? (10 points)}



\item \question{Should you study for the exam? (10 points)}

}


%Left out for variety
\com{

\question{
The following example is due to Caspar Hare:
\begin{quote}

\textbf{Symmetrical Worlds} Imagine that the universe is divided in two along a plane. As far as anyone can tell, the universe is completely symmetrical across this plane: what happens on one side is an exact mirror image of what happens on the other side. The plane is a great tourist attraction. People go up to the plane to peer into the other side, and invariably see their symmetrical twin peering back at them. 

The plane alternates between being opaque and transparent, and scientists have established that when the plane is opaque, there are no causal interactions between events on different sides of the plane. A favorite activity of visitors is to wait until the plane turns opaque, and unveil some crazy prop or hold some ridiculous pose, only to find their twin displaying the same crazy prop or holding the same ridiculous pose when the plane turns transparent.

You are having fun with your symmetry twin when then plane turns opaque. A mysterious but credible stranger comes up to you and offers you a deal. ``Here is a thousand dollars,'' she says.``It's yours to keep. But consider this: my symmetrical twin is right now giving your twin, on the other side of the opaque plane, a thousand dollars. If your twin burns her thousand dollars, I will give you a million dollars. Here is a lighter!"
\end{quote}

In answering the following questions, assume that you value only money and that you value it linearly. (You might find it helpful to look at the characterization of Evidential and Causal Decision Theory in Section~5.4.3 of the course materials.)
}

\begin{enumerate}

\item \question{According to an evidential decision theorist, should you burn the thousand or not burn the thousand? (10 points; don't forget to justify your answer)}

  


\item \question{According to a causal decision theorist, should you burn the thousand or not burn the thousand? (10 points; don't forget to justify your answer)}

}

\end{enumerate}






\com{
\item Here is a famous puzzle, introduced in Gregory Kavka's ``The Toxin Puzzle" (1983):

\begin{quote}
An eccentric billionaire places before you a vial of toxin that. If you drink it, it will make you ill for a day. It will not, however, threaten your life or have any lasting effects. The billionaire will pay you one \$1M dollars Monday morning if, on Sunday evening, you \emph{intend} to drink the toxin the next day. He emphasizes that you need not drink the toxin in order to receive the money; in fact, if you form the intention the money would be in your bank account before the time for drinking it arrives. All you have to do is \emph{intend} on Sunday night to drink the toxin on Monday afternoon. You are perfectly free to change your mind after receiving the money, and not drink the toxin after all.
\end{quote}

Suppose you really need the money---enough to warrant a day of illness. It is now Sunday afternoon. Should you decide to  drink the toxin? (10 points)


}






%%%%%%%%%


\footnote{
\emph{Proof:} We start by using the facts that $p(\text{LPred}|\text{Left}) =  p(\overline{\text{LPred}}|\overline{\text{Left}})$ and $p(\text{Left}) =  p(\overline{\text{Left}})$ to show that  $p(\text{LPred} \ \text{Left}) =  p(\overline{\text{LPred}} \ \overline{\text{Left}})$:

\[ \begin{array}{rcl}
p(\text{LPred}|\text{Left}) &=  &p(\text{RPred}|\text{Right})\\
p(\text{LPred}|\text{Left}) &=  &p(\overline{\text{LPred}}|\overline{\text{Left}})\\
\frac{p(\text{LPred}\ \text{Left})}{p(\text{Left})} &=  &\frac{p(\overline{\text{LPred}} \ \overline{\text{Left}})}{p(\overline{\text{Left}})}\\
p(\text{LPred} \ \text{Left}) &=  &p(\overline{\text{LPred}} \ \overline{\text{Left}})\\
p(\text{LPred} \ \text{Left}) &=  &p(\overline{\text{LPred}} \ \overline{\text{Left}})
 \end{array}\] 
Now, generally speaking, $p(A | B) = 1 - p(\overline{A} | B)$, assuming $p(B) \neq 0$:
\[ \begin{array}{rcl}
p(AB \vee \overline{A}B) &= &p(AB) + p(\overline{A}  B)\\
p(B) &= &p(AB) + p(\overline{A}  B)\\
p(A B) &= &p(B) - p(\overline{A}  B)\\
\frac{p(A  B)}{p(B)} &= &1 - \frac{p(\overline{A}  B)}{p(B)}\\
p(A | B) &= &1 - p(\overline{A} | B)
 \end{array}\] 
So we can also use our assumptions to show $p(\text{LPred} \ \overline{\text{Left}}) =  p(\overline{\text{LPred}} \ \text{Left})$:
\[ \begin{array}{rcl}
1 - p(\text{LPred} | \text{Left}) &=  &1 -p(\text{LPred} | \text{Left})\\
1 - p(\text{LPred} | \text{Left}) &=  &1 -p(\overline{\text{LPred}} | \overline{\text{Left}})\\
p(\overline{\text{LPred}} | \text{Left}) &=  &p(\text{LPred} | \overline{\text{Left}})\\
p(\text{Left}) \cdot p(\overline{\text{LPred}} | \text{Left}) &=  &p(\text{Left}) \cdot p(\text{LPred} | \overline{\text{Left}})\\
p(\text{Left}) \cdot p(\overline{\text{LPred}} | \text{Left}) &=  &p(\overline{\text{Left}}) \cdot p(\text{LPred} | \overline{\text{Left}})\\
p(\overline{\text{LPred}} \ \text{Left}) &=  &p(\text{LPred} \ \overline{\text{Left}})\\
 \end{array}\] 

The result is then straightforward:
\[ \begin{array}{rcl}
p(\text{LPred}\ \overline{\text{Left}}) &=  &p(\overline{\text{LPred}}\ \text{Left})\\
p(\text{LPred Left}) + p(\text{LPred}\ \overline{\text{Left}}) &=  &p(\overline{\text{LPred}}\ \text{Left}) + p(\text{LPred}\ \text{Left}))\\
p(\text{LPred Left}) + p(\text{LPred}\ \overline{\text{Left}}) &=  &p(\overline{\text{LPred}}\ \text{Left}) + p(\overline{\text{LPred}}\ \overline{\text{Left}}))\\
p(\text{LPred}) &=  &p(\overline{\text{LPred}})
 \end{array}\] 

}




