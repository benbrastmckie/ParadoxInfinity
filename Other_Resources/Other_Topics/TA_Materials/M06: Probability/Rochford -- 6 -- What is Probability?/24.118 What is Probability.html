<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"/>
	<title>24.118: What is Probability?</title>
	<meta name="author" content="Damien Rochford (based on notes by Agustín Rayo)"/>
	<link rel="stylesheet" type="text/css" href="philosstyle.css">
	<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>
<body>

<em class="philosophysmall"> 24.118:</em> <em
 class="titlesmall">What is Probability?</em> <img style="padding-right:60px" src="https://www.mathsisfun.com/data/images/probability-line.gif" alt=
"A line, representing possible values of probabilities, from 0 on one end, representing impossibility, to 1 on the other end, representing certainty." width="50%" align="right">

<ul>
<li><a href="#section_subob">Subjective and Objective Probability</a>

<ul>
<li><a href="#section_connection">The Connection</a></li>
</ul></li>
<li><a href="#section_subjective">Subjective Probability</a>

<ul>
<li><a href="#section_credences">Credences</a></li>
<li><a href="#section_dutch">The Dutch Book Argument</a>

<ul>
<li><a href="#section_functions">Probability Functions</a></li>
<li><a href="#section_betting">Betting Behaviour</a></li>
<li><a href="#section_book1">Dutch Book 1</a></li>
<li><a href="#section_book2">Dutch Book 2</a></li>
</ul></li>
<li><a href="#section_indifference">The Principle of Indifference</a></li>
</ul></li>
<li><a href="#section_objective">Objective Probability</a>

<ul>
<li><a href="#section_frequentism">Frequentism</a></li>
<li><a href="#section_indeterministic">Indeterministic Laws</a>

<ul>
<li><a href="#section_humean">Humean Chance</a></li>
<li><a href="#section_antihumean">Anti-Humean Chance</a></li>
</ul></li>
<li><a href="#section_initial">Probabilities Over Initial Conditions</a></li>
</ul></li>
</ul>

<h1 id="section_subob">Subjective and Objective Probability</h1>

<p>We make use of the idea of probability all the time. We feel safe traveling by plane because we believe that the probability of an accident is small; we buy fire insurance because we believe that, although the probability of a fire is small, it is not small enough to be ignored.</p>

<p>But what <em>is</em> probability? What does it mean to say, for example:
<blockquote>
The probability that the coin will land Heads is 50%.
</blockquote>
If you think about it for a moment, it can seem a bit mysterious what that is supposed to mean. Either the coin will land heads or it won’t; it can’t “50%” land heads. So what are we talking about?</p>

<p>It has taken a while to sort out, but philosophers now think that there are <em>two</em>, quite different things you can mean when you say that the probability that the coin will land Heads is 50%, and that there are two corresponding sense of “probability”. Philosophers call these “subjective probability” and “objective probability”.</p>

<p>The distinction between these kinds of probability exactly corresponds to the distinction between epistemic and metaphysical <em>possibility</em>, that we discussed in Topic 1. Subjective probability is epistemic probability — that is, it has to do with the state of knowledge of some particular agent. Something has a certain subjective probability relative to the state of knowledge of a particular agent at a particular time. Roughly, the subjective probability of that agent in a proposition \(p\) is the <em>degree of confidence</em> she should have in \(p\).</p>

<p>Objective probability, on the other hand, is metaphysical probability — that is, it has to do with how stuff is, completely independently of what anyone thinks or knows about it.</p>

<p>That is just a sketch of the difference between subjective and objective probability; there’s a lot more to say.</p>

<ul>

<h2 id="section_connection">The Connection</h2>

<p>Though objective and subjective probability are distinct, they are connected. They are connected in a way which explains why it is easy, in certain cases, to get confused between them, or why it is, in some cases, not important to distinguish between them. In the literature, the connection is called the “Principal Principle”. To a first approximation, it is this:</p>
<blockquote>
<p><strong>Principal Principle</strong><br>
If you know that the objective probability of \(p\) is \(x\), then your subjective probability of \(p\) should be \(x\).</p>
</blockquote>

<p>So in situations where we are talking about an agent who has all the relevant information to figure out what the objective probabilities are, and in which she is smart enough to figure out the objective probabilities, given that information, the subjective probability and the objective probability will be the same.</p>

</ul>

<br>

<h1 id="section_subjective">Subjective Probability</h1>

<ul>

<h2 id="section_credences">Credences</h2>

<p>The central idea behind subjective probability is that beliefs aren’t just on or off — i.e., you don’t just believe something or not. Instead, beliefs come in degrees. You can be certain of something, or very confident, or just a bit more confident than not, or 50&#8211;50, or find it very implausible, or you can be certain that something is <em>not</em> the case.</p>

<p>Further, we assume that we can model your degree of belief in something with a real number, between 0 and 1. 0 represents complete confidence that a given proposition is <em>not</em> true; 1 represents complete confidence that a proposition is true.</p>

<p>An agent’s total state of belief, then, can be modelled with a function that takes a proposition to the interval [0,1]. In the philosophy literature, such a function is called a <strong>credence function</strong>, and an agent’s degree of belief in a particular proposition \(p\), as represented by a number in [0,1], is called the agent’s <strong>credence</strong> in \(p\).</p>

<br>

<h2 id="section_dutch">The Dutch Book Arguments</h2>

<p>So far so good. But how do probabilities come into this? Well, there is an argument that purports to show that, if you are <em>rational</em>, then you’re credence function has got to be a <em>probability function</em>. Let me explain what that means.</p>

<ul>

<h3 id="section_functions">Probability Functions</h3>

<p>The domain of a probability function is the set of all propositions, which are things that can be true or false. Propositions form a Boolean algebra. That means that, for every proposition \(p\), there is a contradictory proposition \(\neg p\) (read ‘not \(p\)’) that is true if and only if \(p\) isn’t; and for every pair of propositions \(p\), \(q\), there is a proposition \(p\vee q\) (read ‘\(p\) or \(q\)’) that is true if and only if either \(p\) is true or \(q\) is true (or both).</p>

<p>The range of a probability function is the real interval [0,1].</p>

<p>Now, credence functions also have the set of all propositions as their domain and [0, 1] as their range. But that’s not enough to make a function \(f\) a probability function. It has to meet two further conditions:</p>

<ol>
<li>if a proposition \(p\) is necessary — that is, there is no possible way for things to be such that it is false — then \(f(p)=1\), and</li>
<li>if two propositions \(p\), \(q\), are mutually exclusive — that is, there is no possible way for things to be such that they are both true — then \(f(p\vee q)=f(p)+f(q)\).<sup><a href="#fn:1" id="fnref:1" title="see footnote" class="footnote">1</a></sup></li>
</ol>

<p>That’s all it takes for a function to be a probability function (modulo the above footnote). All the standard rules about probability with which you might be familiar follow from those two constraints above.</p>

</ul>

<p>So if a credence function meets constraints 1 and 2 above, it is a probability function. But there is no particular reason to think that credence functions in general must meet constraints 1 and 2. For example, there’s nothing to stop someone from being very confident that their keys are in their pocket, and also very confident that they gave their keys to their partner, so their keys aren’t in their pocket; that would, in fact, involve a violation of the above conditions (exercise for the reader: explain why).</p>

<p>The claim that is widespread among philosophers is that an agent’s credence function <em>should</em> be a probability function. Another way of putting this: a perfectly rational agent’s credence function is a probability function.</p>

<p>Why? The traditional argument, which dates back to philosopher and all-round genius <a href="https://en.wikipedia.org/wiki/Frank_P._Ramsey">Frank Ramsey</a>, is called the “Dutch Book Argument”. The Dutch Book Argument makes certain assumptions about the relationship between an agent’s credence and her behaviour, so let’s talk about that.</p>

<ul>

<h3 id="section_betting">Betting Behaviour</h3>

<p>The assumption we make is this: if an agent has a credence \(x\) in a proposition \(p\), then she will be willing to buy a bet where she wins \(\$S\) if is true, and nothing otherwise, for anything less than \(x \times $S\); and she will be willing to sell a bet where she has to pay \(\$S\) if \(p\) is true, and nothing otherwise, for anything more than \(x \times $S\). Moreover, she is willing to go either way — either buy or sell — such a bet for exactly \(x \times $S\).</p>

<p>In table form, when an agent <em>buys</em> a bet, the payoffs are as follows:</p>
<center>
	<table width=20%>
		<tr> <th>Truth Value of \(p\)</th> <th>Net Payoff</th></tr>
		<tr> <td style="text-align:center">True</td> <td style="text-align:center">\(\$S-x\$S\)</td> </tr>
		<tr> <td style="text-align:center">False</td> <td style="text-align:center">\(-x\$S\)</td> </tr>
	</table>
</center>

&#8230;and when she <em>sells</em> a bet, the payoffs are as follows:
<center>
	<table width=20%>
		<tr> <th>Truth Value of \(p\)</th> <th>Net Payoff</th></tr>
		<tr> <td style="text-align:center">True</td> <td style="text-align:center">\(x\$S-\$S\)</td> </tr>
		<tr> <td style="text-align:center">False</td> <td style="text-align:center">\(x\$S\)</td> </tr>
	</table>
</center>
</p>

</ul>

<p>Now we can give the argument. The idea behind the Dutch Book argument is this: if an agent’s credence function is not a probability function, then she is exploitable in a predictable way — a way that shows that there is something wrong with her credence function. The argument is called the “Dutch Book Argument” because, apparently, “Dutch Book” is a term for an arrangement of bets in which the bookie is sure to win, and the bettor is sure to lose, no matter what happens (apologies to the Dutch if this is a slander on your good name). What the arguments show is that an agent is exploitable by a Dutch Book if her credences are not a probability function.</p>

<p>The argument has two parts — one for each of the conditions that a credence function must meet to be a probability function.</p>

<ul>

<h3 id="section_book1">Dutch Book 1</h3>

<p>Recall that for an agent’s credence function to be a probability function, she must have credence 1 in all necessarily true propositions. In this section we show that an agent must have credence 1 in a necessarily true proposition in order to avoid being Dutch-booked.</p>

<p>Suppose we offer to buy the following bet from an agent: you pay me \(\$1\) if a necessary proposition \(p\), is true, and nothing otherwise. If the agent has credence \(x\) in \(p\), then, by the above assumptions concerning betting behaviour, she will be willing to sell this bet for \(x\times \$1\). So her net payoffs are as follows:
<center>
	<table width=20%>
		<tr> <th>Truth Value of \(p\)</th> <th>Net Payoff</th></tr>
		<tr> <td style="text-align:center">True</td> <td style="text-align:center">\(x\times \$1 - \$1 = \$(x-1)\)</td> </tr>
		<tr> <td style="text-align:center">False</td> <td style="text-align:center">\((x\times $1=\$x)\)</td> </tr>
	</table>
</center></p>

<p>Because \(p\) is necessary, we can ignore the last row, as it cannot occur; every possible situation is a situation in which \(p\) is true. So whatever happens, the agent is going to get a net payoff of \(\$(x-1)\). So the only way the agent can avoid losing money is by having a credence of 1 in \(p\); if she has anything less, she will predictably lose money by taking this bet. So it is only agents with credence 1 in necessary propositions that can avoid being exploited in this way.</p>

<br>

<h3 id="section_book2">Dutch Book 2</h3>

<p>Now to show that an agent must have credence \(C(p\vee q) = C(p)+C(q)\), when \(p\), \(q\) are mutually exclusive, in order to not be Dutch-book-able. This one is more complicated.</p>

<p>Suppose \(p\) and \(q\) are mutually exclusive. Consider the following series of bets:</p>

<ul>
<li>Bet 1: get $1 if \(p\) is true, nothing otherwise.</li>
<li>Bet 2: get $1 if \(q\) is true, nothing otherwise.</li>
<li>Bet 3: get $1 if \(p\vee q\) is true, nothing otherwise.</li>
</ul>

<p>Now, suppose the agent has credence \(x\) in \(p\), credence \(y\) in \(q\), and credence \(z\) in \(p\vee q\). And suppose we offer her the following deals: we will sell her Bet 1 for \(\$x\), we will sell her Bet 2 for \(\$y\), and we will buy Bet 3 from her for \(\$z\). She will accept these bets, by the above assumptions about betting behaviour. Her possible payoffs will be as follows:

<center>
	<table width=55%>
		<tr> <th>Truth Value of \(p\)</th> <th>Truth Value of \(q\)</th> <th>Net Payoff</th></tr>
		<tr> <td style="text-align:center">True</td> <td style="text-align:center"> True</td> <td style="text-align:right">\((\$1-\$x) + (\$1-\$y) + (-$1+$z) = $(1-x-y+z)\)</td> </tr>
		<tr> <td style="text-align:center">True</td> <td style="text-align:center">False</td> <td style="text-align:right">\((\$1-\$x) + (-\$y) + (-\$1+\$z) = \$(-x-y+z)\)</td> </tr>
		<tr> <td style="text-align:center">False</td> <td style="text-align:center">True</td> <td style="text-align:right">\((-\$x) + (1-\$y) + (-\$1+\$z) = \$(-x-y+z)\)</td> </tr>
		<tr> <td style="text-align:center">False</td> <td style="text-align:center">False</td> <td style="text-align:right">\((-\$x) + (-\$y) + \$z) = \$(-x-y+z)\)</td> </tr>
	</table>
</center>
Since \(p\) and \(q\) are mutually exclusive, we can ignore the top row; the only possible outcomes are the last three rows. So no matter what happens, the agent is going to get \(\$(-x-y+z)\). So if \(z&lt;x+y\), the agent is sure to lose money, no matter what.</p>

<p>What this shows is that \(z\) must be greater than or equal to \(x+y\) for the agent to not be predictably exploitable. But a very similar argument show that \(z\) must be less than or equal to \(x+y\) for the agent to not be predictably exploitable; instead of offering to sell the agent the first two bets, you offer to buy them, and instead of offering to buy the last bet, you offer to sell it.</p>

<p>So the only way for an agent to not be exploitable by some Dutch Book is for her \(z\) to equal her \(x\) plus her \(y\) — i.e., it is for her to meet the second of the conditions on credence functions which make them probability functions.</p>

</ul>

<p>So that’s the argument that rational credence functions are probability functions. Not everyone is happy with this argument — it seems strange that an argument about what it is rational to <em>believe</em> relies on assumptions about how you will <em>behave</em>, given your beliefs. Usually we think of the question of what it is rational to believe as completely independent of the question of how you should, or would, behave, given those beliefs.</p>

<p>But even those people who think that there is something fishy about the Dutch Book argument usually agree with its conclusion. Trying to give a different kind of argument for that conclusion, that does not rely on assumptions about behaviour, is a project with a lot of attention right now, in philosophy.<sup><a href="#fn:2" id="fnref:2" title="see footnote" class="footnote">2</a></sup></p>

<p>In any case: when we talk about subjective probability, we assume that the agent we’re talking about is perfectly rational. That means that, though we call this “subjective probability”, there’s a sense in which it isn’t subjective at all. There are facts of the matter, philosophers think, about what a rational agent’s credences will be in a given situation. The only sense in which subjective probability is subjective is that it is indexed to a particular subject — i.e., a particular agent.</p>

<br>

<h2 id="section_indifference">The Principle of Indifference</h2>

<p>We have considered one constraint on rational belief: that one’s credence function be a probability function. But that leaves a lot of leeway. There are all sorts of completely crazy credences that are probability functions. Can we come up with any further constraints on rational belief?</p>

<p>An important candidate for a further constraint is called the Principle of Indifference. The basic idea is very simple. When we have a bunch of propositions, and exactly one of them is true, and we have no more reason to believe one than another, we should assign them equal credence.</p>

<p>Suppose, for example, that we have a coin, and we have no more reason to believe that it will land Heads than that it will land Tails. According to the Principle of Indifference, we should divide our credence equally, and give both the proposition that the coin will land Heads and the proposition that it will land Tails credence 0.5.</p>

<p>The Principle of Indifference was the basis of an attempt, in the middle of the 20th Century, to form an <em>inductive logic</em>. The idea behind inductive logic was that you could think of confirmation as a logical relationship between two propositions, just like entailment can be thought of as a relationship between two propositions. The principle of indifference was a key part of the project of describing the confirmation relationship between propositions.<sup><a href="#fn:3" id="fnref:3" title="see footnote" class="footnote">3</a></sup></p>

<p>The person who got the furthest in this project was <a href="https://en.wikipedia.org/wiki/Rudolf_Carnap">Rudolph Carnap</a>. Had he succeeded, we would have air-tight rules for telling us how confident we should be in a given theory, given the data. That would be pretty cool.</p>

<p>Unfortunately, philosophers now think this project cannot succeed, for many reasons. One of them is that the Principle of Indifference is inconsistent. Here is a case that shows that, due to philosopher <a href="https://en.wikipedia.org/wiki/Bas_van_Fraassen">Bas Van Frassen</a>. Imagine a cube factory. We know that the factory produces cubes with a side-length of less than 1 meter, but we haven’t the slightest idea how the cube sizes are chosen. What is the probability that the next cube produced will have a side-length of less than half a meter?</p>

<p>Here is an argument based on the Principle of Indifference. We have no more reason to think that the side length of the next cube is any one number in the interval [0,1] than another. So, by the Principle of Indifference, we should regard equal intervals as equally likely. In particular, we should regard the length being less than half a meter as equally likely to it being more than half a meter. So it follows from the Principle of Indifference that our subjective probability should be 50% that the next cube produced will have a side-length of less than half a meter, and that our subjective probability should be 50% that the next cube will have a side-length greater than half a meter but smaller than a meter. (We ignore the possibility that the factory will next produce a cube whose side-length is exactly half a meter. This is because there is a zero probability that the factory will next produce a cube whose side-length is exactly half a meter; if you want to know why, as me or a TA.)</p>

<p>So far, so good. The bad news is that the Principle of Indifference delivers a different conclusion when we focus on volume rather than side-length.</p>

<p>As before, start with the observation that the distance between 0 and 1/2 is the same as the distance between 1/2 and 1. Accordingly, our reasons for thinking that the factory will next produce a cube with a volume of less than half a cubic meter are exactly analogous to our reasons for thinking that the factory will next produce a cube with a volume of more than half a cubic meter. So it follows from the Principle of Indifference that we should be 50% confident that the next cube produced will have a volume of less than half a cubic meter, and 50% confident that the next cube will have a volume greater than half a cubic meter.</p>

<p>The problem, of course, is that cubes with a side-length of half a meter do not have a volume of half a cubic meter, but a volume of 1/8 cubic meters. Accordingly, cubes with a side-length of less than half a meter are only a fraction of the cubes whose volume is less than half a cubic meter. So if we are 50% confident that the next cube will have a volume of less than half a cubic meter, then we should be less than 50% confident that the next cube will have a side-length of less than half a meter, which contradicts our first result.</p>

<p>Perhaps there is a version of the Principle of Indifference that allows us to avoid this kind of problem. It is an ongoing project for some philosophers to try to find such a version; so far nobody has been able to formulate one that seems very convincing.</p>

</ul>

<br>

<h1 id="section_objective">Objective Probability</h1>

<p>Seaborgium is an element. One of its isotopes, \(^{265}\mbox{Sg}\), has a half-life of 8.9 seconds. That means that is you take a particle of \(^{265}\mbox{Sg}\) and wait 8.9 seconds, the probability that it will decay is 50%.</p>

<p>When we say that Seaborgium has a certain half-life, we don’t seem to be talking about the credences of any particular subject, even a hypothetical one. On the face of it, we seem to be describing a feature of the world itself, rather than a feature of anyone&#8217;s psychology — a feature that would be true even if there were no people around to think about it.</p>

<p>But what kind of feature of the world are we talking about, exactly? It can seem a bit mysterious. Either the particle will decay or it won’t; what does it mean for there to be a fact that it is 50% likely to decay, independently of what anyone thinks about it?</p>

<p>(A note on terminology: philosophers sometimes call objective probabilities “chances”; I will use that terminology sometimes below.)</p>

<ul>

<h2 id="section_frequentism">Frequentism</h2>

<p>Here is an oldschool theory of objective probability. According to frequentism, what it means for a particle of \(^{265}\mbox{Sg}\) to have a 50% probability of decaying within the next 8.9 seconds is for the frequency of decay to be 50%. That is: in 50% of all events in throughout the history of the universe that are relevantly similar to this one, involving a particle of Seaborgium 265, the particle decays within 8.9 seconds.</p>

<p>This theory has many, many problems. One huge problem is that, while it is perhaps not so hard for the example of Seaborgium 265 particle decay, in general nobody has a good account of what makes two events “relevantly similar”. But put that problem to the side; there’s plenty others.</p>

<p>Imagine that there was only ever one particle of \(^{265}\mbox{Sg}\). Suppose it decayed before 8.9 seconds had passed. Would it follow that the objective probability of \(^{265}\mbox{Sg})\ decay would be 100%? Frequentism says yes, but that is hard to believe.</p>

<p>An improvement on straight frequentism is what is called &ldquo;hypothetical frequentism&rdquo;. The idea is this: you don’t look at what the <em>actual</em> frequency of decay is, to know what the probability of decay is. Instead you look at what the frequency of decay would have been, if there had been a “sufficiently large” number of decays.</p>

<p>Hypothetical frequentism can’t be right either. The problem is that it is perfectly possible for a very large collection of \(^{265}\mbox{Sg}\) particles to all decay before 8.9 seconds. It is extremely unlikely that that happen, to be sure. But it is certainly possible; that just follows from the fact that the chance of decay within 8.9 seconds is 50%, and that decays are independent of each-other.</p>

<p>In general, it is always <em>possible</em> for frequency to come apart from the probability. If that’s true, then frequency — even hypothetical frequency — can’t be <em>identical</em> to probability.</p>

<br>

<h2 id="section_indeterministic">Indeterministic Laws</h2>

<p>A <strong>dynamical law</strong> is a law that says what will happen in the future, given how things are at a particular time. A dynamical law is <strong>deterministic</strong> if it specifies a unique state that the universe will be in at any future time, given how things are at a particular time. Newtonian Mechanics and General Relativity involve deterministic laws, in this sense.</p>

<p>Let a dynamical law be <strong>indeterministic</strong> if, instead of specifying a unique future state, it instead lists a bunch of possible future states, and specifies the <em>objective probability</em> that the universe will be in each of them. Quantum mechanics, as it is usually interpreted, involves dynamical laws of exactly this kind.</p>

<p>One way of understanding what it is for there to exist (non-trivial) objective probabilities is to think of it as meaning that the fundamental dynamical laws are indeterministic.</p>

<p>Now, there are two versions of this idea, depending on what view you have about laws of nature: Humean, or Anti-Humean. (The names honour <a href="https://en.wikipedia.org/wiki/David_Hume">David Hume</a>, one of the greatest philosophers of all time.) Let me explain.</p>

<ul>

<h3 id="section_humean">Humean Chances</h3>

<p><strong>Humeanism</strong> is the view that all there is to the universe is all the little local facts about how things are at each point in space-time. If you specify what things are like at each point in space-time, you’ve specified everything there is to specify about the universe.</p>

<p>These facts, about what is going on at each space-time point, are sometimes called the “Humean mosaic”. Humeanism is the view that everything is determined by the Humean mosaic.</p>

<p>Something that is <em>not</em> included in the Humean mosaic are extra fact about the <em>causal relationships</em> between space-time points, or about the <em>laws of nature</em> that govern those relationships. Laws of nature have to do not so much with the structure of the universe, but rather with how we <em>describe</em> the universe, according to the Humean. Let me explain.</p>

<p>Consider all the ways there are of describing the Humean mosaic. Some ways of describing it are very <strong>strong</strong> — that is, they provide us with a lot of information. That’s good. Some ways of describing it are very <strong>simple</strong> — that is, they are short, and relatively easy to understand. That’s good too.</p>

<p>Unfortunately, it’s difficult for a description to be both very strong and very simple. A description that consisted of a huge list detailing, for each space-time point, what it was like, would be very strong, but it wouldn&#8217;t be simple. In contrast, a description  like “some stuff happened” would be very simple, but wouldn&#8217;t be very strong.</p>

<p>The best theories are ones that strike the best balance between simplicity and strength. For a principle to be a law of nature is, for a Humean, for that principle to feature in the best description of the whole universe — i.e., a description of the Humean mosaic that strikes the best balance between simplicity and strength.</p>

<p>Now, it might be that the best balance of simplicity and strength involves probabilities. To see how this might be so, suppose, for example, that someone flips a coin a thousand times, and we want to describe the outcomes. One way to do that would be to specify the initial conditions of the coin and its environment, including the flipper, to a very high degree of precision, and then specify a rule for determining what that system is like at later times, using Newtonian mechanics. That might, in fact, entail everything there is to know about the sequence of coin flips, but it is awfully complicated.</p>

<p>An alternative is to describe things by saying that the objective probability that the coin landed heads, on any given flip, was 50%. That’s not a very strong theory — there’s lots of details about the sequence of coin flips it leaves unspecified. But it <em>does</em> put you in a position to be very confident about a lot of interesting things, concerning this sequence of coin flips, and it is <em>much</em> simpler than the Newtonian alternative. Maybe the cost in strength is worth the gain in simplicity.</p>

<p>For the Humean who believes in non-trivial objective chances, the dynamical laws are like the less strong but much much simpler description of the coin flips above. They are a description of the universe that strikes the best balance between simplicity and strength, and do so by invoking probabilities.</p>

<br>

<h3 id="section_antihumean">Anti-Humean Chances</h3>

<p>Anti-Humeanism is the view that that Humeanism is false. The question of which laws are obeyed by the universe cannot be reduced to the question of what each space-time point is like, locally speaking, according to the Anti-Humean. There is an extra fact: the causal relationships among the space-time points, and the laws of nature that govern them. That’s a fact about the universe, according to the Anti-Humean, not a fact about us</p>

<p>For the Humean, there is a sense in which it is not a very big deal that the world is governed by indeterministic laws rather than deterministic ones. There is, according to the Humean, some set of deterministic laws that get everything right; it’s just that they are less convenient to use than the indeterministic laws.</p>

<p>On the other hand, the determinism or non-determinism of the laws <em>is</em> a big deal for the Anti-Humean. If the world is indeterministic, it has nothing to do with the way we describe things, according to the Anti-Humean; it is a fundamental fact about the nature of the universe. </p>

<p>More specifically, it is a fact about the causal nature of the universe. The state of the universe at an earlier time causally influences the state at later times. Earlier states don’t <em>determine</em> later states, if this Anti-Humean indeterminist is right, but they do give them a nudge in some directions rather than others. Objective probabilities are facts about that nudge.</p>

<p>The Anti-Humean does have much more to say about the nature of objective probability. It’s not something that can be defined in more fundamental terms, according to her. So if you feel like you need such a definition to be convinced that objective probabilities make sense, then this way of believing in objective probabilities is not for you. But most quantum physicists don’t seem overly bothered by the fact that the probabilities that feature in their theory can’t be explained in more fundamental terms, on the usual interpretation; you shouldn’t be bothered either, according to the Anti-Humean.</p>

</ul>

<br>

<h2 id="section_initial">Probabilities Over Initial Conditions</h2>

<p>There is a third way of understanding objective probabilities; unlike the other two, it is completely compatible with determinism. It doesn’t put the probabilities in the dynamical laws of the universe. Instead, the claim is that there are objective probabilities for how the universe <em>starts</em>.</p>

<p>On this way of thinking, what makes it true that there is an objective probability of 50% that the coin land Heads is that there is a 50% probability of the universe having initial conditions that lead to a situation in which the coin lands Heads (given that it leads to a situation like the one we're talking about, with similar macrscopic facts).</p>

<p>This way of understanding objective probabilities is more or less the way they are understood in statistical mechanics. It is also more or less the way probabilities are understood on the Bohmian interpretation of quantum mechanics, according to which the dynamical laws are deterministic after all, despite appearances to the contrary.</p>

<p>Now, this approach raises some questions</p>

<ol>
<li>There are a lot of different ways of assigning probabilities to initial conditions. Which one is the right one?</li>
<li>What does it even <em>mean</em> to say that the universe’s initial conditions have a certain probability?</li>
</ol>

<p>When it comes to theories like statistical mechanics and the Bohmian interpretation of quantum theory, we think we have an answer to the first question. The right way of assigning initial probabilities is the one that gives you the right predictions. For instance, when it comes to statistical mechanics, if you use the Lebesgue measure over phase space — that is, roughly, that you assign equal probability to any possible position and momentum of all the particles in the universe — then you predict, correctly, that it is extremely unlikely that all the air in a room will congregate in one corner, or that the water in a glass at room temperature will divide into an ice-cube and some steam, though these things are, in fact, compatible with Newtonian mechanics. There are other ways of assigning probabilities that get you the <em>wrong</em> results. Don’t use those!</p>

<p>Question 2 is a lot harder to answer. When you say that there is a probability measure over the initial states of the universe, you are <em>not</em> saying something about what caused the initial state, because there is no earlier state to cause the initial state. So what are you saying? Further adding to the air of mystery is that the beginning of the universe is the ultimate in one-off events; it’s not even <em>possible</em> that it be replicated. This has many people worried about the significance of probability measures over initial conditions. But they seem to work!</p>

<div class="footnotes">
<hr />
<ol>

<li id="fn:1">
<p>This version of 2, which I have given for the sake of simplicity, is a bit weaker than what is usually assumed about probability functions. You can read more about the stronger version of 2, called "Countable Additivity", <a href="http://www.mit.edu/~djr/24.118/two-envelope.html#section_countable">here</a>. <a href="#fnref:1" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

<li id="fn:2">
<p>See, for instance, <a href="http://www-personal.umich.edu/~jjoyce/papers/aac.pdf">this article</a> by James Joyce (the contemporary philosopher, not the author of the same name). <a href="#fnref:2" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

<li id="fn:3">
<p>Actually, the way people thought of it back then, confirmation was a relationship between <em>sentences</em>, not propositions. This was, in fact, part of the problem. You may not be so clear on what the distinction between sentences and propositions is. If you want to know more about this, ask me or one of your TAs. <a href="#fnref:3" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>


</body>
</html>