\documentclass[11pt]{article}

\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}

\usepackage[margin=1.5in,headsep=.5in]{geometry}

\usepackage{fancyhdr}

\setlength{\headheight}{20pt}

\usepackage[colorlinks]{hyperref} 
\usepackage{cleveref}

\usepackage{enumitem}
\setlist[enumerate]{itemsep=0mm}

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{reg}{Rule}
\newtheorem{exer}{Exercise}
\newtheorem{note}{Note}
\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{thm}{Theorem}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[theorem]{Conjecture}
\newtheorem*{axm}{Axiom of Choice}
\newtheorem{exm}{Example}
\newtheorem*{defn*}{Definition}

\pagestyle{fancy}

\begin{document}

\pagenumbering{gobble}

\lhead{$24.118$ Paradox and Infinity }
\rhead{Recitation $9$: G\"odel's Theorem}



\begin{center}
{\LARGE \bf Mind and Machine}
\end{center}

\smallskip

\section{The Computational Theory of Mind}

\begin{description}
\item[CTM] The mind just is a Turing-style computational system.  In short, human minds are Turing machines.
\end{description}

A few clarifications:
\begin{enumerate}
\item[i.] Describing the mind as a computing system does not suggest that the mind is programmable. Most Turing machines are not programmable.
\item[ii.] CTM does not simply hold that the mind is like a computing system. It holds that the mind literally is a computing system. A suitable abstract computational model offers a literally true description of core mental processes. 
\item[iii.] CTM is best described as the view that the mind is a Turing-machine-like system, rather than simply a Turing machine. This is because, quite boringly, the precise formalism of a Turing machine is too restrictive when applied to human minds. For example, the inputs and outputs of a Turing machine, strictly speaking, are always inscribed symbols, whereas the mind receives sensory input and produces motor outputs.
\item[iv.] CTM is best understood as a family of views. There are, in fact, many versions of it, depending on the details.
\end{enumerate}

CTM is common in modern cognitive psychology and is even presumed by many theorists of evolutionary psychology.

\section{The Penrose–Lucas Argument}

The Penrose–Lucas argument is an argument against the computational theory of mind, based on G\"odel's incompleteness theorem. The target of the Penrose–Lucas argument is actually even weaker than CTM. If this argument succeeds, then it is logically impossible to construct a Turing machine that has the same cognitive abilities as humans. 

\begin{defn*}[The G\"odel Sentence]
Let $F$ be an axiomatic system that is at least as strong as the standard axiomatization of arithmetic. The G\"odel sentence of $F$, $G(F)$, is the sentence in the language of $F$ that expresses of itself that it is not probable in $F$.
\end{defn*}

\begin{theorem*}[Corollary to G\"odel's First Incompleteness Theorem]
If an axiomatic system $F$ that is at least as strong as the standard axiomatization of arithmetic is consistent, then it is unable to prove its G\"odel sentence.
\end{theorem*}

The argument:
\begin{enumerate}
\item The theory of Turing machines, $T$, is a consistent axiomatic system that is at least as strong as the standard axiomatization of arithmetic.
\item If a consistent axiomatic system is at least as strong as the standard axiomatization of arithmetic, it is unable to prove its G\"odel sentence.
\item Therefore, the theory of Turing machines, $T$, cannot prove its G\"odel sentence, $G(T)$.
\item For any sentence $\phi$ in the language of $T$, if a Turing machine can show that $\phi$ is true, then $T$ is able to prove $\phi$.
\item Therefore, no Turing machine can show that $G(T)$ is true.
\item But human minds can show that $G(T)$ is true.
\item Therefore, the mind is not a Turing machine.
\end{enumerate}

\noindent
Why endorsing Line 6: Suppose $G(T)$ is provable in $T$. If $T$ is consistent, then, $G(T)$ has to be true if all of $T$'s axioms are true. But $G(T)$ says that $G(T)$ is not provable in $T$. Hence if $G(T)$ is true, $G(T)$ is not provable in $T$. Contradiction. Therefore $G(T)$ is not provable in $T$. But this is precisely what $G(T)$ claims. Hence $G(T)$ is true. The human mind is capable of understanding this argument. Hence we can show that $G(T)$ is true.

\section{Criticisms}

Objection One: Perhaps the mind is inconsistent. \\

\noindent
Objection Two: The above argument only shows that the mind is not a Turing machine, in the strictest sense. But recall that CTM is the view that the mind is a Turing-like machine. Let's say there is a Turing-style formal system that governs the mind, $T'$. The above argument only shows that $T'$ is stronger than $T$, as it can see the truth of $G(T)$, but it doesn't show that $T'$ can see the truth of $G(T')$. But the latter is really what we need.\\

\noindent
Objection Three: The above argument for endorsing Line 6 is both sketchy and informal. To get a real argument of Line 6, we need to make use of a stronger formal system, say, set theory. Because set theory is (strictly) stronger than the theory of Turing machines, that we can prove $G(T)$ in set theory does not contradict G\"odel's theorem. But we haven't shown that we can also somehow see the truth of the G\"del sentence of set theory.



\end{document}

